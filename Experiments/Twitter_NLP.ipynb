{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Testing Notebook\n",
    "#### NLTK Position Tags:\n",
    "```('And', 'CC'), ('now', 'RB'), ('for', 'IN'), ('something', 'NN'), ('completely', 'RB'), ('different', 'JJ')```\n",
    "\n",
    "*and* is CC, a coordinating conjunction; *now* and *completely* are RB, or adverbs; *for* is IN, a preposition; *something* is NN, a noun; and *different* is JJ, an adjective.\n",
    "\n",
    "```('They', 'PRP'), ('refuse', 'VBP'), ('to', 'TO'), ('permit', 'VB'), ('us', 'PRP'), ('to', 'TO'), ('obtain', 'VB'), ('the', 'DT'), ('refuse', 'NN'), ('permit', 'NN')```\n",
    "\n",
    "*refuse* and *permit* both appear as a present tense verb (VBP) and a noun (NN). E.g. *refUSE* is a verb meaning \"deny,\" while *REFuse* is a noun meaning \"trash\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pattern.web import Twitter\n",
    "from pattern.en import tag\n",
    "from pattern.vector import NB, count\n",
    "import sys\n",
    "import time\n",
    "\n",
    "twitter, classifier = Twitter(language=\"en\"), NB(baseline=\"UNDEFINED\")\n",
    "\n",
    "def train_model(n_pts, search_terms, category, category_count):\n",
    "    print(\"Training \" + str(n_pts*100) + \" data points for \" + str(category))\n",
    "    for i in range(1, n_pts):\n",
    "        for tweet in twitter.search(search_terms, start=i, count=100):\n",
    "            s = tweet.text.lower()\n",
    "            p = category\n",
    "            category_count+=1\n",
    "            v = tag(s)\n",
    "            v = [word for word, pos in v if (pos == \"NN\" or pos == \"VB\")]\n",
    "            v = count(v) # {'sweet': 1}\n",
    "            if v:\n",
    "                classifier.train(v, type=p)\n",
    "                sys.stdout.write('\\r')\n",
    "                sys.stdout.write(str(int(category_count/(n_pts*100)*100)) + \"% : \" + str(v))\n",
    "    sys.stdout.write('\\r')\n",
    "    print(\"Finished!\")\n",
    "    print(\"Number of data points: \" + str(category_count) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 3000 data points for HAPPY\n",
      "Finished!uck': 1}, 'art': 1, 'demon': 1, 'rt': 1, 'diggity': 1}2, 'bb11': 1, 'biggboss11': 1, 'https://t.co/9dowprwtog': 1}friday': 1, 'package': 1, 'rt': 2}1, 'rt': 1}m!â€¦': 1}1} 'eye': 1}ffix': 1, 'rt': 1}'@marionspekker': 1, '@marienassar': 1}\n",
      "Number of data points: 2742\n",
      "\n",
      "Training 3000 data points for SAD\n",
      "Finished!sshole': 1, 'flooring': 1, 'wood': 1}: 1, 'love': 1, 'life': 1}ult': 1, 'https://t.co/xa5yhucnoj': 1, 'whitney': 2, 'houston': 1} 1}}ng': 1} 1}, 'dami': 1, 'worldwidemayor': 1}1, 'https://t.co/7di1muz8em': 1, '@salnpage': 1}\n",
      "Number of data points: 2900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n = 30\n",
    "happy = 0\n",
    "sad = 0\n",
    "\n",
    "train_model(n, \"shiok OR swee OR perfect OR #happy\", \"HAPPY\", happy)\n",
    "time.sleep(1)\n",
    "train_model(n, \"sian OR shag OR suay OR fml OR #sad\", \"SAD\", sad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word pangseh is SAD\n",
      "The word nasi lemak is SAD\n",
      "The word food is SAD\n",
      "The word breakfast is SAD\n",
      "The word lunch is HAPPY\n",
      "The word dinner is HAPPY\n",
      "The word MRT is SAD\n",
      "The word school is SAD\n",
      "The word trip is HAPPY\n",
      "The word work is SAD\n",
      "The word home is SAD\n",
      "The word family is SAD\n",
      "The word garden is SAD\n",
      "The word play is SAD\n",
      "The word train is SAD\n",
      "The word bus is SAD\n",
      "The word KFC is SAD\n",
      "The word SAF is SAD\n",
      "The word book out is HAPPY\n",
      "The word camp is SAD\n",
      "The word army is HAPPY\n",
      "The word navy is SAD\n",
      "The word air force is HAPPY\n"
     ]
    }
   ],
   "source": [
    "def evaluate(word):\n",
    "    category = classifier.classify(word)\n",
    "    return (\"The word \" + str(word) + \" is \" + str(category))\n",
    "    \n",
    "words = (\"pangseh\",\"nasi lemak\",\"food\",\"breakfast\",\"lunch\",\"dinner\",\"MRT\",\"school\",\"trip\",\"work\",\"home\",\"family\",\"garden\",\"play\",\"train\",\"bus\",\"KFC\",\"SAF\",\"book out\",\"camp\",\"army\",\"navy\",\"air force\",)\n",
    "    \n",
    "for word in words:\n",
    "    print(evaluate(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
