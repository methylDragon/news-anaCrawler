{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NLP\n",
    "from pattern.web import Twitter\n",
    "from textblob import TextBlob\n",
    "import nltk.data\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "#NLTK RESOURCE DOWNLOADING\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "\n",
    "#PARSER\n",
    "from newspaper import Article\n",
    "import newspaper\n",
    "\n",
    "#set tokenizer model\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analyseArticle(url):\n",
    "#list, download, and parse article\n",
    "    a = Article(url) # Set language as english\n",
    "    a.download()\n",
    "    a.parse()\n",
    "    a.nlp()\n",
    "    \n",
    "    #Overall sentiment trackers\n",
    "    count = 0\n",
    "    overallScore = [0.0,0.0]\n",
    "    \n",
    "    #Split article into sentences\n",
    "    for index, token in enumerate(tokenizer.tokenize(a.text)):\n",
    "        analysis = TextBlob(tokenizer.tokenize(a.text)[index])\n",
    "        # analysis.correct() #Correct mispelt words !!! IF YOU ACTIVATE THIS IT'LL BE SLOW \n",
    "        #and for each sentence, analyze sentiment\n",
    "        #Prep overall analysis tracker, IGNORE if parameters are [0.0, 0.0] for sentence\n",
    "        if analysis.sentiment.polarity != 0.0 and analysis.sentiment.subjectivity != 0.0:\n",
    "            count += 1\n",
    "            overallScore[0] += analysis.sentiment.polarity\n",
    "            overallScore[1] += analysis.sentiment.subjectivity\n",
    "\n",
    "    #Guarding against divisions by 0\n",
    "    if count == 0:\n",
    "        count = 1    \n",
    "    \n",
    "    #Store variables\n",
    "    title = a.title\n",
    "    authors = a.authors\n",
    "    date = a.publish_date\n",
    "    summary = a.summary\n",
    "    polarity = overallScore[0]/count\n",
    "    subjectivity = overallScore[1]/count\n",
    "    keywords = a.keywords\n",
    "    images = a.top_image\n",
    "    videos = a.movies\n",
    "    text = a.text\n",
    "    language = getattr(a,\"meta_lang\")\n",
    "\n",
    "    #parameters = [title, url, authors, date, summary, polarity, subjectivity, keywords, images, videos, text, language]\n",
    "\n",
    "    #Output parameter variables in a dictionary as function output\n",
    "    return {\"title\":title, \"url\":url, \"authors\":authors, \"date\":date, \"summary\":summary, \"polarity\":polarity, \"subjectivity\":subjectivity, \"keywords\":keywords, \"images\":images, \"videos\":videos, \"text\":text, \"language\": language}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper = newspaper.build(\"http://\" + \"www.thehearttruths.com\", memoize_articles=False)\n",
    "\n",
    "analyseArticle(\"www.thehearttruths.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
