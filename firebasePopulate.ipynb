{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# firebasePopulate\n",
    "\n",
    "***Author: methylDragon (methylDragon.com)***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description: Crawls, and analyses articles from stated URLs (and Mothership, because it's special/troublesome), churns out parameters via analyseArticle, and pushes them to Firebase.\n",
    "\n",
    "{\"title\", \"url\", \"authors\", \"date\", \"summary\", \"polarity\", \"subjectivity\", \"keywords\", \"images\", \"videos\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           .     .\n",
      "                        .  |\\-^-/|  .    \n",
      "                       /| } O.=.O { |\\  \n",
      "                      /´ \\ \\_ ~ _/ / `\\\n",
      "                    /´ |  \\-/ ~ \\-/  | `\\\n",
      "                    |   |  /\\\\ //\\  |   | \n",
      "                     \\|\\|\\/-\"\"-\"\"-\\/|/|/\n",
      "                             ______/ /\n",
      "                             '------'\n",
      "                _   _        _  ___                         \n",
      "      _ __  ___| |_| |_ _  _| ||   \\ _ _ __ _ __ _ ___ _ _  \n",
      "     | '  \\/ -_)  _| ' \\ || | || |) | '_/ _` / _` / _ \\ ' \\ \n",
      "     |_|_|_\\___|\\__|_||_\\_, |_||___/|_| \\__,_\\__, \\___/_||_|\n",
      "                        |__/                |___/          \n",
      "     -------------------------------------------------------\n",
      "                        methylDragon.com\n",
      "                   \n",
      "\n",
      "INITIALISING MODULES\n",
      ".\n",
      "OPENING LOGS\n",
      ".\n",
      "LOADING URL LISTS\n",
      ".\n",
      ".\n",
      ".\n",
      "INITIALISED FIREBASEPOPULATE\n"
     ]
    }
   ],
   "source": [
    "%run 'Experiments/methylSwag.ipynb'\n",
    "methylSwag()\n",
    "\n",
    "print(\"\\nINITIALISING MODULES\\n.\")\n",
    "%run 'analyseArticle.ipynb'\n",
    "%run 'firebasePush.ipynb'\n",
    "\n",
    "import traceback\n",
    "import newspaper\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "\n",
    "print(\"OPENING LOGS\\n.\")\n",
    "log = open(\"CRAWL_LOG.txt\", \"w\")\n",
    "\n",
    "print(\"LOADING URL LISTS\\n.\")\n",
    "\n",
    "COMPLETED = []\n",
    "\n",
    "QUEUE = []\n",
    "\n",
    "#newsURLs = '''[\"kementah.blogspot.sg\", \"blog.wan-ifra.org/\",\"www.straitstimes.com\",\"www.todayonline.com\",\"www.channelnewsasia.com\",\"www.businessinsider.sg\",'''\n",
    "\"\"\"newsURLs = [\"www.businesstimes.com.sg\",\n",
    "            \"alvinology.com\",\"www.asiaone.com/singapore\",\"sg.news.yahoo.com\",\"www.gov.sg/news\",\n",
    "            \"www.theindependent.sg\",\"www.tnp.sg\",\"telegraph.co.uk/news/worldnews/asia/singapore/\",\n",
    "            \"themiddleground.sg\",\"www.allsingaporestuff.com\",\"www.theonlinecitizen.com\",\"statestimesreview.com\",\n",
    "            \"www.tremeritus.com\",\"thehearttruths.com\",\"therealsingapore.com\",\"mustsharenews.com\",\n",
    "            \"berthahenson.wordpress.com\",\"yawningbread.wordpress.com\",\"singaporedaily.net\",\n",
    "           \"www.msn.com/en-sg/news/\",\n",
    "         \n",
    "newsURLs= [\"asiancorrespondent.com/section/singapore/#fOzMdSd453Zgkgvy.97\",\n",
    "\n",
    "newsURLs= [\"www.mrbrownshow.com/\",\n",
    "            \"www.buzzfeed.com/tag/singapore\",\"stomp.straitstimes.com/\",\n",
    "         \"www.straitstimes.com/forum\",\"fintechnews.sg/\",\"www.techinasia.com/tag/singapore\",\n",
    "        \"www.theedgesingapore.com/latest-news\",\n",
    "\"\"\"         \n",
    "'''newsURLs = [\"www.mfa.gov.sg/content/mfa/overseasmission/vientiane/News.html\",\n",
    "        \"www.google.com.sg/search?q=singapore+news&client=ubuntu&hs=HVO&channel=fs&dcr=0&source=lnms&tbm=nws&sa=X&ved=0ahUKEwj-tcLb6u3WAhWDs48KHUDqBzg4HhD8BQgKKAE&biw=1855&bih=981\"]'''\n",
    "\n",
    "newsURLs = [\"www.channelnewsasia.com\",\"statestimesreview.com\"]\n",
    "\n",
    "mothershipURLs = [\"mothership.sg/category/news\",\"mothership.sg/category/perspectives\",\n",
    "                  \"mothership.sg/category/community\",\"mothership.sg/category/almost-famous\",\n",
    "                  \"mothership.sg/category/mps-in-the-house\",\"mothership.sg/category/humour\"]\n",
    "\n",
    "\n",
    "\n",
    "print(\".\\n.\\nINITIALISED FIREBASEPOPULATE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawl and analyse the latest Mothership Articles this month, outputting parameters, and pushing to Firebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mcount = 0\\nmnoteng = 0\\nmfailed = 0\\nmtooshort = 0\\nmfetcherror = 0\\n\\nprint(\"RUN MOTHERSHIP MODULE\\n\")\\n\\nfor URL in mothershipURLs:\\n    print(\"Retrieving URL...\\n\")\\n    try:\\n        sourceCode = requests.get(\"http://\" + str(URL))\\n        soup = BeautifulSoup(sourceCode.content, \"lxml\")\\n        print(\"Target URL: \" + str(URL))\\n\\n        for div in soup.find_all(\"div\", class_=\"ind-article\"):\\n            for a in div.find_all(\"a\"):\\n                if \"mothership.sg\" in a.get(\"href\"):\\n                    try:\\n                        print(str(mcount + mnoteng + mfailed + mtooshort + mfetcherror + 1)+\": \", end=\"\")\\n                        parameters = analyseArticle(a.get(\"href\")) #for getting link\\n                        \\n                        if parameters == \"ZERO_SENTIMENT_ERROR\": #Check for zero sentiment, means article is too short or redirected\\n                            mtooshort += 1\\n                            print(\"SKIPPING: ZERO_SENTIMENT_ERROR, NO SENTIMENT DETECTED!\", end=\" #\")\\n                            print(str(mtooshort))\\n                            continue\\n                            \\n                        if parameters == \"FETCH_ERROR\": #Check for zero sentiment, means article is too short or redirected\\n                            mfetcherror += 1\\n                            print(\"SKIPPING: FETCH_ERROR, COULD NOT DOWNLOAD ARTICLE!\", end=\" #\")\\n                            print(str(mfetcherror))\\n                            continue\\n            \\n                        if str(parameters[\"language\"]) != \"en\": #Check if article is in English, if it isn\\'t skip\\n                            mnoteng += 1\\n                            print(\"SKIPPING: LANG_ERROR, ARTICLE NOT IN ENGLISH!\", end=\" #\")\\n                            print(str(mnoteng) + \" (\" + str(parameters[\"language\"]) + \")\")\\n                            continue\\n                        \\n                        title = str(parameters[\"title\"])\\n                        url = str(parameters[\"url\"])\\n                        authors = parameters[\"authors\"]\\n                        date = str(parameters[\"date\"])\\n                        summary = str(parameters[\"summary\"])\\n                        polarity = str(parameters[\"polarity\"])\\n                        subjectivity = str(parameters[\"subjectivity\"])\\n                        keywords = parameters[\"keywords\"]\\n                        images = str(parameters[\"images\"])\\n                        videos = str(parameters[\"videos\"])\\n                        text = str(parameters[\"text\"])\\n\\n                        firebasePush(title, url, authors, date, summary, polarity, subjectivity, keywords, images, videos, text)\\n                        mcount += 1\\n                        print(\"Processed article #\", end=\"\")\\n                        print(mcount)\\n                        \\n                    except Exception as ex:\\n                        mfailed += 1\\n                        print(\"FAILED article: #\", end=\" | \")\\n                        print(ex)\\n                        print(mfailed,end=\" | Moving on...\\n\")\\n            \\n                        log.write(\"\\n\\n-----------------------------------------------\")\\n                        log.write(\"\\n\\nMOTHERSHIP MODULE UNKNOWN ERROR DUMP | Fetch #\")\\n                        log.write(str(mcount + mnoteng + mfailed + mtooshort + mfetcherror))\\n                        log.write(\": \\n\\n\")\\n                        log.write(\"ERROR:\")\\n                        log.write(str(traceback.format_exc()))  #FOR DEBUGGING\\n                        log.write(\"\\n\\n\")\\n                        log.write(\"Data:\")\\n                        log.write(str(parameters))              #FOR DEBUGGING\\n                        \\n    except Exception as ex:\\n        print(\"Failed URL\", end=\" | \")\\n        print(ex)\\n        \\n    print(\"\\n--------------!!-rawr-=rAwR=*RAWR*=rAwR=-rawr-!!--------------\")\\n    string = \"FINISHED: \" + str(URL)\\n    print(string.center(63))\\n    log.write(\"PROCESSED: \")\\n    log.write(str(URL))\\n    log.write(\"\\n\")\\n    log.flush()\\n    \\n    print(\"--------------!!-rawr-=rAwR=*RAWR*=rAwR=-rawr-!!--------------\\n\")\\n\\nmethylHalf()\\n\\nprint(\"\\n  ---!!--!!-raa--rawr-=rAwR=*RAAWR*=rAwR=-rawr--raa-!!--!!---\")\\nprint(\"                FINISHED PROCESSING MOTHERSHIP\")\\nlog.write(\"FINISHED PROCESSING: \")\\nlog.write(\"MOTHERSHIP\")\\nlog.write(\"\\n\\n\")\\nprint(\"  ---!!--!!-raa--rawr-=rAwR=*RAAWR*=rAwR=-rawr--raa-!!--!!---\\n\")\\n\\nprint(\"SUMMARY:\")\\nprint(\"Elapsed time: \",end=\"\")\\ncheckpoint = timer()\\nprint(checkpoint - start,end=\"\")\\nprint(\" seconds\\n\")\\nlog.write(\"Elapsed Time: \" + str(checkpoint - start))\\nlog.write(\"\\n\\n\")\\nlog.flush\\n\\nprint(str(mcount + mnoteng + mfailed + mtooshort + mfetcherror) + \" Total Articles Accessed\")\\nprint(str(mcount) + \" Processed Articles\\n\")\\n\\nprint(str(mnoteng) + \" LANG_ERRORs (Article not in English)\")\\nprint(str(mtooshort) + \" ZERO_SENTIMENT_ERRORs (No sentiment detected)\")\\nprint(str(mfetcherror) + \" FETCH_ERRORs (Failed to fetch article)\")\\nprint(str(mfailed) + \" Failed Articles\\n\")\\n\\nfirebaseRefresh()\\ntime.sleep(1)\\n\\nprint(\"  ---!!--!!-raa--rawr-=rAwR=*RAAWR*=rAwR=-rawr--raa-!!--!!---\\n\")'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''mcount = 0\n",
    "mnoteng = 0\n",
    "mfailed = 0\n",
    "mtooshort = 0\n",
    "mfetcherror = 0\n",
    "\n",
    "print(\"RUN MOTHERSHIP MODULE\\n\")\n",
    "\n",
    "for URL in mothershipURLs:\n",
    "    print(\"Retrieving URL...\\n\")\n",
    "    try:\n",
    "        sourceCode = requests.get(\"http://\" + str(URL))\n",
    "        soup = BeautifulSoup(sourceCode.content, \"lxml\")\n",
    "        print(\"Target URL: \" + str(URL))\n",
    "\n",
    "        for div in soup.find_all(\"div\", class_=\"ind-article\"):\n",
    "            for a in div.find_all(\"a\"):\n",
    "                if \"mothership.sg\" in a.get(\"href\"):\n",
    "                    try:\n",
    "                        print(str(mcount + mnoteng + mfailed + mtooshort + mfetcherror + 1)+\": \", end=\"\")\n",
    "                        parameters = analyseArticle(a.get(\"href\")) #for getting link\n",
    "                        \n",
    "                        if parameters == \"ZERO_SENTIMENT_ERROR\": #Check for zero sentiment, means article is too short or redirected\n",
    "                            mtooshort += 1\n",
    "                            print(\"SKIPPING: ZERO_SENTIMENT_ERROR, NO SENTIMENT DETECTED!\", end=\" #\")\n",
    "                            print(str(mtooshort))\n",
    "                            continue\n",
    "                            \n",
    "                        if parameters == \"FETCH_ERROR\": #Check for zero sentiment, means article is too short or redirected\n",
    "                            mfetcherror += 1\n",
    "                            print(\"SKIPPING: FETCH_ERROR, COULD NOT DOWNLOAD ARTICLE!\", end=\" #\")\n",
    "                            print(str(mfetcherror))\n",
    "                            continue\n",
    "            \n",
    "                        if str(parameters[\"language\"]) != \"en\": #Check if article is in English, if it isn't skip\n",
    "                            mnoteng += 1\n",
    "                            print(\"SKIPPING: LANG_ERROR, ARTICLE NOT IN ENGLISH!\", end=\" #\")\n",
    "                            print(str(mnoteng) + \" (\" + str(parameters[\"language\"]) + \")\")\n",
    "                            continue\n",
    "                        \n",
    "                        title = str(parameters[\"title\"])\n",
    "                        url = str(parameters[\"url\"])\n",
    "                        authors = parameters[\"authors\"]\n",
    "                        date = str(parameters[\"date\"])\n",
    "                        summary = str(parameters[\"summary\"])\n",
    "                        polarity = str(parameters[\"polarity\"])\n",
    "                        subjectivity = str(parameters[\"subjectivity\"])\n",
    "                        keywords = parameters[\"keywords\"]\n",
    "                        images = str(parameters[\"images\"])\n",
    "                        videos = str(parameters[\"videos\"])\n",
    "                        text = str(parameters[\"text\"])\n",
    "\n",
    "                        firebasePush(title, url, authors, date, summary, polarity, subjectivity, keywords, images, videos, text)\n",
    "                        mcount += 1\n",
    "                        print(\"Processed article #\", end=\"\")\n",
    "                        print(mcount)\n",
    "                        \n",
    "                    except Exception as ex:\n",
    "                        mfailed += 1\n",
    "                        print(\"FAILED article: #\", end=\" | \")\n",
    "                        print(ex)\n",
    "                        print(mfailed,end=\" | Moving on...\\n\")\n",
    "            \n",
    "                        log.write(\"\\n\\n-----------------------------------------------\")\n",
    "                        log.write(\"\\n\\nMOTHERSHIP MODULE UNKNOWN ERROR DUMP | Fetch #\")\n",
    "                        log.write(str(mcount + mnoteng + mfailed + mtooshort + mfetcherror))\n",
    "                        log.write(\": \\n\\n\")\n",
    "                        log.write(\"ERROR:\")\n",
    "                        log.write(str(traceback.format_exc()))  #FOR DEBUGGING\n",
    "                        log.write(\"\\n\\n\")\n",
    "                        log.write(\"Data:\")\n",
    "                        log.write(str(parameters))              #FOR DEBUGGING\n",
    "                        \n",
    "    except Exception as ex:\n",
    "        print(\"Failed URL\", end=\" | \")\n",
    "        print(ex)\n",
    "        \n",
    "    print(\"\\n--------------!!-rawr-=rAwR=*RAWR*=rAwR=-rawr-!!--------------\")\n",
    "    string = \"FINISHED: \" + str(URL)\n",
    "    print(string.center(63))\n",
    "    log.write(\"PROCESSED: \")\n",
    "    log.write(str(URL))\n",
    "    log.write(\"\\n\")\n",
    "    log.flush()\n",
    "    \n",
    "    print(\"--------------!!-rawr-=rAwR=*RAWR*=rAwR=-rawr-!!--------------\\n\")\n",
    "\n",
    "methylHalf()\n",
    "\n",
    "print(\"\\n  ---!!--!!-raa--rawr-=rAwR=*RAAWR*=rAwR=-rawr--raa-!!--!!---\")\n",
    "print(\"                FINISHED PROCESSING MOTHERSHIP\")\n",
    "log.write(\"FINISHED PROCESSING: \")\n",
    "log.write(\"MOTHERSHIP\")\n",
    "log.write(\"\\n\\n\")\n",
    "print(\"  ---!!--!!-raa--rawr-=rAwR=*RAAWR*=rAwR=-rawr--raa-!!--!!---\\n\")\n",
    "\n",
    "print(\"SUMMARY:\")\n",
    "print(\"Elapsed time: \",end=\"\")\n",
    "checkpoint = timer()\n",
    "print(checkpoint - start,end=\"\")\n",
    "print(\" seconds\\n\")\n",
    "log.write(\"Elapsed Time: \" + str(checkpoint - start))\n",
    "log.write(\"\\n\\n\")\n",
    "log.flush\n",
    "\n",
    "print(str(mcount + mnoteng + mfailed + mtooshort + mfetcherror) + \" Total Articles Accessed\")\n",
    "print(str(mcount) + \" Processed Articles\\n\")\n",
    "\n",
    "print(str(mnoteng) + \" LANG_ERRORs (Article not in English)\")\n",
    "print(str(mtooshort) + \" ZERO_SENTIMENT_ERRORs (No sentiment detected)\")\n",
    "print(str(mfetcherror) + \" FETCH_ERRORs (Failed to fetch article)\")\n",
    "print(str(mfailed) + \" Failed Articles\\n\")\n",
    "\n",
    "firebaseRefresh()\n",
    "time.sleep(1)\n",
    "\n",
    "print(\"  ---!!--!!-raa--rawr-=rAwR=*RAAWR*=rAwR=-rawr--raa-!!--!!---\\n\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawl and analyse the other URLs, outputting parameters, and pushing to Firebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN URL MODULE\n",
      "\n",
      "Building domain...\n",
      "\n",
      "Domain building complete for: www.channelnewsasia.com\n",
      "1: Processed article #1\n",
      "2: Processed article #2\n",
      "3: SKIPPING: ZERO_SENTIMENT_ERROR, NO SENTIMENT DETECTED! #1\n",
      "http://www.channelnewsasia.com/archives/8395986/news?channelId=7469166\n",
      "4: SKIPPING: ZERO_SENTIMENT_ERROR, NO SENTIMENT DETECTED! #2\n",
      "http://www.channelnewsasia.com/news/technology\n",
      "5: Processed article #3\n",
      "6: SKIPPING: ZERO_SENTIMENT_ERROR, NO SENTIMENT DETECTED! #3\n",
      "http://www.channelnewsasia.com/news/specialreports\n",
      "7: Processed article #4\n",
      "8: SKIPPING: ZERO_SENTIMENT_ERROR, NO SENTIMENT DETECTED! #4\n",
      "http://www.channelnewsasia.com/news/videos/rohingya-refugees-in-india-fight-a-legal-battle-to-avoid-9309560\n",
      "9: SKIPPING: ZERO_SENTIMENT_ERROR, NO SENTIMENT DETECTED! #5\n",
      "http://www.channelnewsasia.com/news/commentary\n",
      "10: Processed article #5\n",
      "11: Processed article #6\n",
      "12: Processed article #7\n",
      "13: Processed article #8\n",
      "14: SKIPPING: ZERO_SENTIMENT_ERROR, NO SENTIMENT DETECTED! #6\n",
      "http://www.channelnewsasia.com/news/catch-up-tv/conversation-with\n",
      "15: SKIPPING: ZERO_SENTIMENT_ERROR, NO SENTIMENT DETECTED! #7\n",
      "http://www.channelnewsasia.com/news/videos/vietnam-s-agricultural-industry-gets-boost-from-big-business-9309562\n",
      "16: Processed article #9\n",
      "17: SKIPPING: ZERO_SENTIMENT_ERROR, NO SENTIMENT DETECTED! #8\n",
      "http://www.channelnewsasia.com/news/videos/aung-san-suu-kyi-to-chair-new-committee-for-rakhine-9309618\n",
      "18: You must `download()` an article first!\n",
      "SKIPPING: FETCH_ERROR, COULD NOT DOWNLOAD ARTICLE! #1\n",
      "19: Processed article #10\n",
      "20: SKIPPING: ZERO_SENTIMENT_ERROR, NO SENTIMENT DETECTED! #9\n",
      "http://www.channelnewsasia.com/news/weather\n",
      "21: Processed article #11\n",
      "22: SKIPPING: ZERO_SENTIMENT_ERROR, NO SENTIMENT DETECTED! #10\n",
      "http://www.channelnewsasia.com/news/lifestyle\n",
      "23: Processed article #12\n",
      "24: SKIPPING: ZERO_SENTIMENT_ERROR, NO SENTIMENT DETECTED! #11\n",
      "http://www.channelnewsasia.com/news/parliament\n",
      "25: Processed article #13\n",
      "26: SKIPPING: ZERO_SENTIMENT_ERROR, NO SENTIMENT DETECTED! #12\n",
      "http://www.channelnewsasia.com/news/catch-up-tv/the-traitor-within\n",
      "27: SKIPPING: ZERO_SENTIMENT_ERROR, NO SENTIMENT DETECTED! #13\n",
      "http://www.channelnewsasia.com/news/advertise/contactsales\n",
      "28: Processed article #14\n",
      "29: Processed article #15\n",
      "30: Processed article #16\n",
      "31: Processed article #17\n",
      "32: Processed article #18\n",
      "33: Processed article #19\n",
      "34: Processed article #20\n",
      "35: Processed article #21\n",
      "36: Processed article #22\n",
      "37: Processed article #23\n",
      "38: Processed article #24\n",
      "39: Processed article #25\n",
      "40: Processed article #26\n",
      "41: Processed article #27\n",
      "42: Processed article #28\n",
      "43: SKIPPING: ZERO_SENTIMENT_ERROR, NO SENTIMENT DETECTED! #14\n",
      "http://www.channelnewsasia.com/news/videos/one-year-after-king-s-death-thais-prepare-for-final-goodbye-9309494\n",
      "44: SKIPPING: ZERO_SENTIMENT_ERROR, NO SENTIMENT DETECTED! #15\n",
      "http://www.channelnewsasia.com/news/business\n",
      "45: SKIPPING: ZERO_SENTIMENT_ERROR, NO SENTIMENT DETECTED! #16\n",
      "http://www.channelnewsasia.com/news/cnainsider/big-singaporean-hearts-at-cox-s-bazar-9264726\n",
      "46: Processed article #29\n",
      "47: SKIPPING: ZERO_SENTIMENT_ERROR, NO SENTIMENT DETECTED! #17\n",
      "http://www.channelnewsasia.com/news/cnainsider/wayang-s-aussie-performer-9310152\n",
      "48: Processed article #30\n",
      "49: Processed article #31\n",
      "50: Processed article #32\n",
      "51: SKIPPING: ZERO_SENTIMENT_ERROR, NO SENTIMENT DETECTED! #18\n",
      "http://www.channelnewsasia.com/news/videos/in-marawi-poverty-leads-many-to-extremism-9309542\n",
      "52: SKIPPING: ZERO_SENTIMENT_ERROR, NO SENTIMENT DETECTED! #19\n",
      "http://www.channelnewsasia.com/news/singapore/eyes-on-the-road-more-drivers-submit-dash-cam-videos-to-police-9309594\n",
      "53: Processed article #33\n",
      "54: Processed article #34\n",
      "55: Processed article #35\n",
      "56: Processed article #36\n",
      "57: Processed article #37\n",
      "58: Processed article #38\n",
      "59: Processed article #39\n",
      "60: Processed article #40\n",
      "61: Processed article #41\n",
      "62: Processed article #42\n",
      "63: Processed article #43\n",
      "64: Processed article #44\n",
      "65: Processed article #45\n",
      "66: Processed article #46\n",
      "67: SKIPPING: ZERO_SENTIMENT_ERROR, NO SENTIMENT DETECTED! #20\n",
      "http://www.channelnewsasia.com/news/cnainsider/language-of-the-heart-learning-dialects-for-the-sake-of-the-9279350\n",
      "68: Processed article #47\n",
      "69: Processed article #48\n",
      "70: Processed article #49\n",
      "\n",
      "--------------!!-rawr-=rAwR=*RAWR*=rAwR=-rawr-!!--------------\n",
      "               FINISHED: www.channelnewsasia.com               \n",
      "--------------!!-rawr-=rAwR=*RAWR*=rAwR=-rawr-!!--------------\n",
      "\n",
      "RUNNING SUMMARY:\n",
      "Elapsed time: 125.58987549401354 seconds\n",
      "\n",
      "70 Total Articles Fetched\n",
      "49 Processed Articles\n",
      "\n",
      "0 LANG_ERRORs (Article not in English)\n",
      "20 ZERO_SENTIMENT_ERRORs (No sentiment detected)\n",
      "1 FETCH_ERRORs (Failed to fetch article)\n",
      "0 Failed Articles\n",
      "\n",
      "--------------!!-rawr-=rAwR=*RAWR*=rAwR=-rawr-!!--------------\n",
      "\n",
      "Building domain...\n",
      "\n",
      "Domain building complete for: statestimesreview.com\n",
      "71: Processed article #50\n",
      "72: Processed article #51\n",
      "73: Processed article #52\n",
      "74: Processed article #53\n",
      "75: Processed article #54\n",
      "76: Processed article #55\n",
      "77: Processed article #56\n",
      "\n",
      "--------------!!-rawr-=rAwR=*RAWR*=rAwR=-rawr-!!--------------\n",
      "                FINISHED: statestimesreview.com                \n",
      "--------------!!-rawr-=rAwR=*RAWR*=rAwR=-rawr-!!--------------\n",
      "\n",
      "RUNNING SUMMARY:\n",
      "Elapsed time: 151.19176326799789 seconds\n",
      "\n",
      "77 Total Articles Fetched\n",
      "56 Processed Articles\n",
      "\n",
      "0 LANG_ERRORs (Article not in English)\n",
      "20 ZERO_SENTIMENT_ERRORs (No sentiment detected)\n",
      "1 FETCH_ERRORs (Failed to fetch article)\n",
      "0 Failed Articles\n",
      "\n",
      "--------------!!-rawr-=rAwR=*RAWR*=rAwR=-rawr-!!--------------\n",
      "\n",
      "                            .     .\n",
      "                         .  |\\-^-/|  .    \n",
      "                        /| } O.=.O { |\\  \n",
      "\n",
      "  ---!!--!!-raa--rawr-=rAwR=*RAAWR*=rAwR=-rawr--raa-!!--!!---\n",
      "                   FINISHED PROCESSING URLS!\n",
      "  ---!!--!!-raa--rawr-=rAwR=*RAAWR*=rAwR=-rawr--raa-!!--!!---\n",
      "\n",
      "SUMMARY:\n",
      "77 Total Articles Accessed\n",
      "56 Processed Articles\n",
      "\n",
      "0 LANG_ERRORs (Article not in English)\n",
      "20 ZERO_SENTIMENT_ERRORs (No sentiment detected)\n",
      "1 FETCH_ERRORs (Failed to fetch article)\n",
      "0 Failed Articles\n",
      "\n",
      "  ---!!--!!-raa--rawr-=rAwR=*RAAWR*=rAwR=-rawr--raa-!!--!!---\n",
      "\n",
      "Elapsed time: 152.55521054001292 seconds\n",
      "\n",
      "SHUTTING DOWN\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "noteng = 0\n",
    "failed = 0\n",
    "tooshort = 0\n",
    "fetcherror = 0\n",
    "\n",
    "print(\"RUN URL MODULE\\n\")\n",
    "\n",
    "for URL in newsURLs:\n",
    "    print(\"Building domain...\\n\")\n",
    "    \n",
    "    try:\n",
    "        paper = newspaper.build(\"http://\" + str(URL), memoize_articles=False)\n",
    "        print(\"Domain building complete for: \" + str(URL))\n",
    "    except Exception as ex:\n",
    "        print(\"Failed DOMAIN\", end=\" | \")\n",
    "        print(ex, end =\" | moving on...\\n\")\n",
    "\n",
    "    for article in paper.articles:\n",
    "        try:\n",
    "            print(str(count + noteng + failed + tooshort + fetcherror + 1)+\": \",end=\"\")\n",
    "            parameters = analyseArticle(article.url)\n",
    "\n",
    "            if parameters == \"ZERO_SENTIMENT_ERROR\": #Check for zero sentiment, means article is too short or redirected\n",
    "                tooshort += 1\n",
    "                print(\"SKIPPING: ZERO_SENTIMENT_ERROR, NO SENTIMENT DETECTED!\", end=\" #\")\n",
    "                print(str(tooshort))\n",
    "                print(article.url)\n",
    "                continue\n",
    "                \n",
    "            if parameters == \"FETCH_ERROR\":\n",
    "                fetcherror +=1\n",
    "                print(\"SKIPPING: FETCH_ERROR, COULD NOT DOWNLOAD ARTICLE!\", end=\" #\")\n",
    "                print(str(fetcherror))\n",
    "                continue\n",
    "                \n",
    "            if str(parameters[\"language\"]) != \"en\": #Check if article is in English, if it isn't skip\n",
    "                noteng += 1\n",
    "                print(\"SKIPPING: LANG_ERROR, ARTICLE NOT IN ENGLISH!\", end=\" #\")\n",
    "                print(str(noteng) + \" (\" + str(parameters[\"language\"]) + \")\")\n",
    "                print(article.url)\n",
    "                continue\n",
    "\n",
    "            title = parameters[\"title\"]\n",
    "            url = str(article.url)\n",
    "            authors = parameters[\"authors\"]\n",
    "            date = str(parameters[\"date\"])\n",
    "            summary = str(parameters[\"summary\"])\n",
    "            polarity = str(parameters[\"polarity\"])\n",
    "            subjectivity = str(parameters[\"subjectivity\"])\n",
    "            keywords = parameters[\"keywords\"]\n",
    "            images = str(parameters[\"images\"])\n",
    "            videos = str(parameters[\"videos\"])\n",
    "            text = str(parameters[\"text\"])\n",
    "\n",
    "            firebasePush(title, url, authors, date, summary, polarity, subjectivity, keywords, images, videos, text)\n",
    "            count += 1\n",
    "            print(\"Processed article #\", end=\"\")\n",
    "            print(count)\n",
    "  \n",
    "        except Exception as ex:\n",
    "            failed += 1\n",
    "            print(\"FAILED article: #\",end=\"\")\n",
    "            print(failed, end=\" | \")\n",
    "            print(ex,end=\" | Moving on...\\n\")\n",
    "\n",
    "            log.write(\"\\n\\n-----------------------------------------------\")\n",
    "            log.write(\"\\n\\nURL MODULE UNKNOWN ERROR DUMP | Fetch #\")\n",
    "            log.write(str(count + noteng + failed + tooshort + fetcherror))\n",
    "            log.write(\": \\n\\n\")\n",
    "            log.write(\"ERROR:\")\n",
    "            log.write(str(traceback.format_exc()))  #FOR DEBUGGING\n",
    "            log.write(\"\\n\\n\")\n",
    "            log.write(\"DATA:\\n\")\n",
    "            log.write(str(parameters))              #FOR DEBUGGING\n",
    "\n",
    "            \n",
    "    print(\"\\n--------------!!-rawr-=rAwR=*RAWR*=rAwR=-rawr-!!--------------\")\n",
    "    string = \"FINISHED: \" + str(URL)\n",
    "    print(string.center(63))\n",
    "    log.write(\"PROCESSED: \")\n",
    "    log.write(str(URL))\n",
    "    log.write(\"\\n\")\n",
    "    log.flush()\n",
    "    print(\"--------------!!-rawr-=rAwR=*RAWR*=rAwR=-rawr-!!--------------\\n\")\n",
    "\n",
    "    print(\"RUNNING SUMMARY:\")\n",
    "    print(\"Elapsed time: \",end=\"\")\n",
    "    checkpoint = timer()\n",
    "    print(checkpoint - start,end=\"\")\n",
    "    print(\" seconds\\n\")\n",
    "    log.write(\"Elapsed Time: \" + str(checkpoint - start))\n",
    "    log.write(\"\\n\\n\")\n",
    "    log.flush\n",
    "    \n",
    "    print(str(count + noteng + failed + tooshort + fetcherror) + \" Total Articles Fetched\")\n",
    "    print(str(count) + \" Processed Articles\\n\")\n",
    "    \n",
    "    \n",
    "    print(str(noteng) + \" LANG_ERRORs (Article not in English)\")\n",
    "    print(str(tooshort) + \" ZERO_SENTIMENT_ERRORs (No sentiment detected)\")\n",
    "    print(str(fetcherror) + \" FETCH_ERRORs (Failed to fetch article)\")\n",
    "    print(str(failed) + \" Failed Articles\\n\")\n",
    "    \n",
    "    firebaseRefresh()\n",
    "    time.sleep(1)\n",
    "    \n",
    "    print(\"--------------!!-rawr-=rAwR=*RAWR*=rAwR=-rawr-!!--------------\\n\")\n",
    "\n",
    "methylHalf()    \n",
    "print(\"\\n  ---!!--!!-raa--rawr-=rAwR=*RAAWR*=rAwR=-rawr--raa-!!--!!---\")\n",
    "print(\"                   FINISHED PROCESSING URLS!\")\n",
    "log.write(\"FINISHED PROCESSING: \")\n",
    "log.write(\"URLS\")\n",
    "log.write(\"\\n\\n\")\n",
    "print(\"  ---!!--!!-raa--rawr-=rAwR=*RAAWR*=rAwR=-rawr--raa-!!--!!---\\n\")\n",
    "\n",
    "print(\"SUMMARY:\")\n",
    "print(str(count + noteng + failed + tooshort + fetcherror) + \" Total Articles Accessed\")\n",
    "print(str(count) + \" Processed Articles\\n\")\n",
    "\n",
    "print(str(noteng) + \" LANG_ERRORs (Article not in English)\")\n",
    "print(str(tooshort) + \" ZERO_SENTIMENT_ERRORs (No sentiment detected)\")\n",
    "print(str(fetcherror) + \" FETCH_ERRORs (Failed to fetch article)\")\n",
    "print(str(failed) + \" Failed Articles\\n\")\n",
    "\n",
    "print(\"  ---!!--!!-raa--rawr-=rAwR=*RAAWR*=rAwR=-rawr--raa-!!--!!---\\n\")\n",
    "\n",
    "print(\"Elapsed time: \",end=\"\")\n",
    "checkpoint = timer()\n",
    "print(checkpoint - start,end=\"\")\n",
    "print(\" seconds\\n\")\n",
    "print(\"SHUTTING DOWN\")\n",
    "log.write(\"Elapsed Time: \" + str(checkpoint - start))\n",
    "log.write(\"\\n\\n\")\n",
    "log.write(\"SHUTTING DOWN\")\n",
    "log.flush\n",
    "\n",
    "log.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
